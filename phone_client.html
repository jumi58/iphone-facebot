<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8" />
  <title>Phone Camera â†’ Laptop (OpenCV.js)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <script src="https://docs.opencv.org/4.x/opencv.js"></script>
  <style>
    body { font-family: system-ui, sans-serif; margin: 16px; }
    video, canvas { width: 100%; max-width: 480px; height: 360px; background: #000; border-radius: 8px; }
    .row { margin: 8px 0; }
    .hint { color: #666; font-size: 12px; }
    .angle { font-size: 22px; font-weight: 700; }
  </style>
</head>
<body>
  <h3>ğŸ“± Phone Client â€” Face Angle Sender (Stabilized)</h3>
  <div class="row">
    WebSocket ì„œë²„(ë…¸íŠ¸ë¶ IP): 
    <input id="ws" placeholder="ws://&lt;laptop_ip&gt;:8765" style="width: 260px;" />
    <button id="connectBtn">ì—°ê²°</button>
    <span id="status" class="hint"></span>
  </div>

  <video id="video" autoplay playsinline></video>
  <canvas id="canvas"></canvas>

  <div class="row">
    <label><input type="checkbox" id="mirror" checked> ë¯¸ëŸ¬ ë³´ê¸°</label>
    <!-- ê¸°ë³¸ê°’ì„ ì¡°ê¸ˆ ë” ì•ˆì •ì ì¸ ê°’ìœ¼ë¡œ ì¡°ì • -->
    <label style="margin-left:12px;">ë¯¼ê°ë„ Î±:
      <input type="range" id="alpha" min="0.05" max="0.6" step="0.01" value="0.18">
    </label>
    <label style="margin-left:12px;">ë°ë“œë°´ë“œ:
      <input type="range" id="dead" min="0" max="0.1" step="0.005" value="0.035">
    </label>
  </div>
  <div class="angle">ANGLE: <span id="angleText">--</span>Â°</div>
  <div class="hint">
    ê°™ì€ Wi-Fiì— ì—°ê²°ëœ ë…¸íŠ¸ë¶ì˜ IPë¥¼ ë„£ê³  ì—°ê²°í•˜ì„¸ìš”. ì˜ˆ: ws://192.168.0.15:8765<br>
    (WebSocketì€ ë‚˜ì¤‘ì— ESP32/ë…¸íŠ¸ë¶ ì—°ë™ìš©ì´ë¼, ì—°ê²° ì•ˆ í•´ë„ ì–¼êµ´ ì¸ì‹ì€ ì‘ë™í•©ë‹ˆë‹¤)
  </div>

<script>
let video       = document.getElementById('video');
let canvas      = document.getElementById('canvas');
let ctx         = canvas.getContext('2d');
let wsInput     = document.getElementById('ws');
let connectBtn  = document.getElementById('connectBtn');
let statusSpan  = document.getElementById('status');
let angleText   = document.getElementById('angleText');
let mirror      = document.getElementById('mirror');
let alphaInput  = document.getElementById('alpha');
let deadInput   = document.getElementById('dead');

let cap, classifier, socket;
let lastAngle   = 90;
let lastSend    = 0;

// ì•ˆì •í™”ë¥¼ ìœ„í•œ ë³€ìˆ˜ë“¤
let stableFace  = null;   // {x,y,width,height} ìµœê·¼ ì–¼êµ´ ìœ„ì¹˜
let lostFrames  = 0;      // ì–¼êµ´ ë†“ì¹œ í”„ë ˆì„ ìˆ˜

// â”€â”€â”€â”€â”€â”€â”€â”€â”€ WebSocket ì—°ê²° â”€â”€â”€â”€â”€â”€â”€â”€â”€
connectBtn.onclick = () => {
  if (socket && socket.readyState === 1) {
    socket.close();
    return;
  }
  const url = wsInput.value.trim();
  if (!url) { alert("ws://<laptop_ip>:8765 í˜•ì‹ìœ¼ë¡œ ì…ë ¥"); return; }
  socket = new WebSocket(url);
  socket.onopen  = () => { statusSpan.textContent = "ì—°ê²°ë¨"; connectBtn.textContent = "ëŠê¸°"; };
  socket.onclose = () => { statusSpan.textContent = "ëŠì–´ì§"; connectBtn.textContent = "ì—°ê²°"; };
  socket.onerror = () => { statusSpan.textContent = "ì˜¤ë¥˜";   };
};

// â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì¹´ë©”ë¼ ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function initCamera(){
  const stream = await navigator.mediaDevices.getUserMedia({
    video: { facingMode: "user" },
    audio: false
  });
  video.srcObject = stream;

  // ë©”íƒ€ë°ì´í„°(í•´ìƒë„) ë¡œë”© ê¸°ë‹¤ë¦¬ê¸°
  await new Promise(r => video.onloadedmetadata = r);

  // ë¹„ë””ì˜¤/ìº”ë²„ìŠ¤ í¬ê¸°ë¥¼ ì‹¤ì œ í•´ìƒë„ì— ë§ì¶”ê¸°
  video.width  = video.videoWidth;
  video.height = video.videoHeight;
  canvas.width  = video.videoWidth;
  canvas.height = video.videoHeight;

  cap = new cv.VideoCapture(video);
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì–¼êµ´ ë¶„ë¥˜ê¸° ë¡œë”© â”€â”€â”€â”€â”€â”€â”€â”€â”€
async function initCascade(){
  // ê°™ì€ í´ë”ì— ìˆëŠ” XML íŒŒì¼ ì‚¬ìš©
  const xml = await fetch("haarcascade_frontalface_default.xml");
  const data = await xml.text();
  cv.FS_createDataFile("/", "face.xml", data, true, false);
  classifier = new cv.CascadeClassifier();
  classifier.load("face.xml");
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê°ë„ ì „ì†¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€
function sendAngle(angle){
  const now = performance.now();
  if (!socket || socket.readyState !== 1) return;
  if (now - lastSend < 80) return; // ~12Hz ì œí•œ
  lastSend = now;
  const payload = JSON.stringify({
    type:  "angle",
    value: Math.round(angle),
    ts:    Date.now()
  });
  socket.send(payload);
}

// â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë©”ì¸ ì²˜ë¦¬ ë£¨í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€
function process(){
  const w = video.width;
  const h = video.height;
  if (!w || !h) return requestAnimationFrame(process);

  const alpha = parseFloat(alphaInput.value);
  const dead  = parseFloat(deadInput.value);

  let src  = new cv.Mat(h, w, cv.CV_8UC4);
  let gray = new cv.Mat();
  cap.read(src);
  if (mirror.checked) cv.flip(src, src, 1);
  cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);

  let faces = new cv.RectVector();

  // âœ… ë” ì•ˆì •ì ì¸ íŒŒë¼ë¯¸í„° (ì‘ì€/ì• ë§¤í•œ ì–¼êµ´ì€ ë¬´ì‹œ)
  // scaleFactor: 1.2, minNeighbors: 5, minSize: 80x80
  classifier.detectMultiScale(
    gray,
    faces,
    1.2,
    5,
    0,
    new cv.Size(80, 80)
  );

  // ë°°ê²½ ì˜ìƒ ë¨¼ì € ê·¸ë¦¼
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

  let usedFace = null;

  if (faces.size() > 0) {
    // ê°€ì¥ í° ì–¼êµ´ í•˜ë‚˜ ì„ íƒ (ê°€ê¹Œìš´ ì‚¬ëŒ)
    let best = faces.get(0);
    for (let i = 1; i < faces.size(); i++) {
      const f = faces.get(i);
      if (f.width * f.height > best.width * best.height) {
        best = f;
      }
    }
    // cv.Rect â†’ ì¼ë°˜ ê°ì²´ë¡œ ë³µì‚¬ (ë©”ëª¨ë¦¬ ì‚­ì œ í›„ì—ë„ ì“°ê¸° ìœ„í•´)
    stableFace = {
      x: best.x,
      y: best.y,
      width:  best.width,
      height: best.height
    };
    lostFrames = 0;
    usedFace = stableFace;
  } else if (stableFace && lostFrames < 5) {
    // ì–¼êµ´ì´ ì ê¹ ì‚¬ë¼ì ¸ë„ ìµœê·¼ ì–¼êµ´ì„ 5í”„ë ˆì„ ìœ ì§€ â†’ í™”ë©´ ëœ íŠ
    lostFrames++;
    usedFace = stableFace;
  } else {
    // ì–¼êµ´ ì™„ì „íˆ ìƒì–´ë²„ë¦¼
    angleText.textContent = "--";
  }

  if (usedFace) {
    // ë¹¨ê°„ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
    ctx.lineWidth   = 3;
    ctx.strokeStyle = 'red';
    ctx.strokeRect(usedFace.x, usedFace.y, usedFace.width, usedFace.height);

    // ì¤‘ì‹¬ x ì¢Œí‘œë¡œ ê°ë„ ê³„ì‚°
    let cx    = usedFace.x + usedFace.width / 2;
    let cNorm = cx / w;            // 0~1
    let desired = cNorm * 180;     // 0~180

    // ê°€ìš´ë° ê·¼ì²˜(ë°ë“œë°´ë“œ)ì—ì„œëŠ” ë³€í™” ë¬´ì‹œ â†’ ëœ í”ë“¤ë¦¼
    if (Math.abs(cNorm - 0.5) < dead) {
      desired = lastAngle;
    }

    // ë¶€ë“œëŸ½ê²Œ ë³´ê°„
    let smooth = lastAngle + alpha * (desired - lastAngle);
    lastAngle = smooth;

    angleText.textContent = Math.round(smooth);
    sendAngle(smooth);
  }

  src.delete();
  gray.delete();
  faces.delete();
  requestAnimationFrame(process);
}

// OpenCV ë¡œë”© ì™„ë£Œ í›„ ì‹œì‘
cv['onRuntimeInitialized'] = async () => {
  await initCamera();
  await initCascade();
  requestAnimationFrame(process);
};
</script>
</body>
</html>
