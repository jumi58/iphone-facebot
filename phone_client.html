<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8" />
  <title>Phone Camera â†’ Laptop (WebSocket)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <script src="https://docs.opencv.org/4.x/opencv.js"></script>
  <style>
    body { font-family: system-ui, sans-serif; margin: 16px; }
    video, canvas { width: 100%; max-width: 480px; height: 360px; background: #000; border-radius: 8px; }
    .row { margin: 8px 0; }
    .hint { color: #666; font-size: 12px; }
    .angle { font-size: 22px; font-weight: 700; }
  </style>
</head>
<body>
  <h3>ğŸ“± Phone Client â€” Face Angle Sender</h3>
  <div class="row">
    WebSocket ì„œë²„(ë…¸íŠ¸ë¶ IP): 
    <input id="ws" placeholder="ws://<laptop_ip>:8765" style="width: 260px;" />
    <button id="connectBtn">ì—°ê²°</button>
    <span id="status" class="hint"></span>
  </div>

  <video id="video" autoplay playsinline></video>
  <canvas id="canvas"></canvas>

  <div class="row">
    <label><input type="checkbox" id="mirror" checked> ë¯¸ëŸ¬ ë³´ê¸°</label>
    <label style="margin-left:12px;">ë¯¼ê°ë„ Î±: <input type="range" id="alpha" min="0.05" max="0.6" step="0.01" value="0.25"></label>
    <label style="margin-left:12px;">ë°ë“œë°´ë“œ: <input type="range" id="dead" min="0" max="0.1" step="0.005" value="0.02"></label>
  </div>
  <div class="angle">ANGLE: <span id="angleText">--</span>Â°</div>
  <div class="hint">ê°™ì€ Wiâ€‘Fiì— ì—°ê²°ëœ ë…¸íŠ¸ë¶ì˜ IPë¥¼ ë„£ê³  ì—°ê²°í•˜ì„¸ìš”. ì˜ˆ: ws://192.168.0.15:8765</div>

<script>
let video = document.getElementById('video');
let canvas = document.getElementById('canvas');
let ctx = canvas.getContext('2d');
let wsInput = document.getElementById('ws');
let connectBtn = document.getElementById('connectBtn');
let statusSpan = document.getElementById('status');
let angleText = document.getElementById('angleText');
let mirror = document.getElementById('mirror');
let alphaInput = document.getElementById('alpha');
let deadInput  = document.getElementById('dead');

let cap, classifier, socket;
let lastAngle = 90;
let lastSend = 0;

connectBtn.onclick = () => {
  if (socket && socket.readyState === 1) { socket.close(); return; }
  const url = wsInput.value.trim();
  if (!url) { alert("ws://<laptop_ip>:8765 í˜•ì‹ìœ¼ë¡œ ì…ë ¥"); return; }
  socket = new WebSocket(url);
  socket.onopen = () => { statusSpan.textContent = "ì—°ê²°ë¨"; connectBtn.textContent = "ëŠê¸°"; };
  socket.onclose = () => { statusSpan.textContent = "ëŠì–´ì§"; connectBtn.textContent = "ì—°ê²°"; };
  socket.onerror = () => { statusSpan.textContent = "ì˜¤ë¥˜"; };
};

async function initCamera(){
  const stream = await navigator.mediaDevices.getUserMedia({
    video: { facingMode: "user" },
    audio: false
  });
  video.srcObject = stream;

  // ë©”íƒ€ë°ì´í„°(ì˜ìƒ í¬ê¸°) ë¡œë”© ê¸°ë‹¤ë¦¬ê¸°
  await new Promise(r => video.onloadedmetadata = r);

  // ë¹„ë””ì˜¤ ìš”ì†Œì˜ width/heightë¥¼ ì‹¤ì œ ì˜ìƒ í¬ê¸°ë¡œ ë§ì¶”ê¸°
  video.width  = video.videoWidth;
  video.height = video.videoHeight;

  // ìº”ë²„ìŠ¤ë„ ë™ì¼ í¬ê¸°ë¡œ ë§ì¶”ê¸°
  canvas.width  = video.videoWidth;
  canvas.height = video.videoHeight;

  // ì´ ìƒíƒœì—ì„œ VideoCapture ìƒì„±
  cap = new cv.VideoCapture(video);
}


async function initCascade(){
  // ê°™ì€ í´ë”ì— ìˆëŠ” íŒŒì¼ì„ ì§ì ‘ ë¶ˆëŸ¬ì˜¤ê¸°
  const xml = await fetch("haarcascade_frontalface_default.xml");
  const data = await xml.text();
  cv.FS_createDataFile("/", "face.xml", data, true, false);
  classifier = new cv.CascadeClassifier();
  classifier.load("face.xml");
}

function sendAngle(angle){
  const now = performance.now();
  if (!socket || socket.readyState !== 1) return;
  if (now - lastSend < 80) return; // ì „ì†¡ ì œí•œ (~12Hz)
  lastSend = now;
  const payload = JSON.stringify({type:"angle", value: Math.round(angle), ts: Date.now()});
  socket.send(payload);
}

function process(){
  const w = video.width; 
  const h = video.height;
  if (!w || !h) return requestAnimationFrame(process);

  const alpha = parseFloat(alphaInput.value);
  const dead  = parseFloat(deadInput.value);

  let src = new cv.Mat(h, w, cv.CV_8UC4);
  let gray = new cv.Mat();
  cap.read(src);
  if (mirror.checked) cv.flip(src, src, 1);
  cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);

  let faces = new cv.RectVector();
  classifier.detectMultiScale(gray, faces, 1.1, 3, 0, new cv.Size(60,60));

  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

  if (faces.size() > 0){
    let best = faces.get(0);
    for (let i=1;i<faces.size();i++){
      const f = faces.get(i);
      if (f.width*f.height > best.width*best.height) best = f;
    }
    ctx.lineWidth = 3; ctx.strokeStyle='red';
    ctx.strokeRect(best.x, best.y, best.width, best.height);

    let cx = best.x + best.width/2;
    let cNorm = cx / w;
    let desired = cNorm * 180;
    if (Math.abs(cNorm - 0.5) < dead) desired = lastAngle;

    let smooth = lastAngle + alpha*(desired - lastAngle);
    lastAngle = smooth;
    angleText.textContent = Math.round(smooth);
    sendAngle(smooth);
  }
  src.delete(); gray.delete(); faces.delete();
  requestAnimationFrame(process);
}

cv['onRuntimeInitialized'] = async () => {
  await initCamera();
  await initCascade();
  requestAnimationFrame(process);
};
</script>
</body>
</html>
